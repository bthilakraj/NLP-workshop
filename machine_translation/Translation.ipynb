{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class we will be using for each language for easier data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper code to read a file containing language a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## We have this to limit sentences to cut down on training time\n",
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s\",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[0].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 1535 sentence pairs\n",
      "Trimmed to 111 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 184\n",
      "est 209\n",
      "[u'i m staying with you .', u'ma jaan sinuga .']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'est')\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        ## Treat the embedding like a lookup table (we can store word embeddings and look them up with indices usually)\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](simple_decoder.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](attention_decoder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def variableFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    result = Variable(torch.LongTensor(indexes).view(-1, 1))\n",
    "    if use_cuda:\n",
    "        return result.cuda()\n",
    "    else:\n",
    "        return result\n",
    "\n",
    "\n",
    "def variablesFromPair(pair):\n",
    "    input_variable = variableFromSentence(input_lang, pair[0])\n",
    "    target_variable = variableFromSentence(output_lang, pair[1])\n",
    "    return (input_variable, target_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One tool which can also help is something called `teacher forcing` in which we use the actual target output instead of the model's guess for the next part of the sequence (it may cause it to converge faster but can lead to instability)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_variable[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0][0]\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            decoder_input = target_variable[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "\n",
    "            decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            if ni == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0] / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [variablesFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_variable = training_pair[0]\n",
    "        target_variable = training_pair[1]\n",
    "\n",
    "        loss = train(input_variable, target_variable, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    input_variable = variableFromSentence(input_lang, sentence)\n",
    "    input_length = input_variable.size()[0]\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_variable[ei],\n",
    "                                                 encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_outputs[ei] + encoder_output[0][0]\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))  # SOS\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "    for di in range(max_length):\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs)\n",
    "        decoder_attentions[di] = decoder_attention.data\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        if ni == EOS_token:\n",
    "            decoded_words.append('<EOS>')\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(output_lang.index2word[ni])\n",
    "\n",
    "        decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to train the model (only run if you want to train from scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27m 1s (- 378m 23s) (5000 6%) 0.9843\n",
      "31m 9s (- 202m 33s) (10000 13%) 0.0803\n",
      "41m 41s (- 166m 45s) (15000 20%) 0.0680\n",
      "45m 15s (- 124m 27s) (20000 26%) 0.0662\n",
      "59m 23s (- 118m 47s) (25000 33%) 0.0653\n",
      "100m 29s (- 150m 43s) (30000 40%) 0.0595\n",
      "104m 51s (- 119m 49s) (35000 46%) 0.0589\n",
      "108m 33s (- 94m 59s) (40000 53%) 0.0571\n",
      "112m 23s (- 74m 55s) (45000 60%) 0.0594\n",
      "116m 10s (- 58m 5s) (50000 66%) 0.0556\n",
      "119m 32s (- 43m 28s) (55000 73%) 0.0528\n",
      "122m 47s (- 30m 41s) (60000 80%) 0.0533\n",
      "126m 3s (- 19m 23s) (65000 86%) 0.0562\n",
      "130m 45s (- 9m 20s) (70000 93%) 0.0550\n",
      "134m 27s (- 0m 0s) (75000 100%) 0.0522\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1)\n",
    "\n",
    "\n",
    "if use_cuda:\n",
    "    encoder1 = encoder1.cuda()\n",
    "    attn_decoder1 = attn_decoder1.cuda()\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> he is a promising student .\n",
      "= ta on lootustandev tudeng .\n",
      "< ta on lootustandev uliopilane . <EOS>\n",
      "\n",
      "> i m a pretty good swimmer .\n",
      "= ma olen paris hea ujuja .\n",
      "< ma olen paris hea ujuja . <EOS>\n",
      "\n",
      "> i m fat .\n",
      "= ma olen paks .\n",
      "< ma olen paks . <EOS>\n",
      "\n",
      "> i m angry .\n",
      "= ma olen vihane .\n",
      "< ma olen vihane . <EOS>\n",
      "\n",
      "> he s three years older than i am .\n",
      "= ta on minust kolm aastat vanem .\n",
      "< ta on minust kolm aastat vanem . <EOS>\n",
      "\n",
      "> he is a promising student .\n",
      "= ta on lootustandev opilane .\n",
      "< ta on lootustandev uliopilane . <EOS>\n",
      "\n",
      "> i m .\n",
      "= olen uheksateistkumnene .\n",
      "< olen . <EOS>\n",
      "\n",
      "> i m taking an exam in january .\n",
      "= ma sooritan jaanuaris eksami .\n",
      "< ma sooritan jaanuaris eksami . <EOS>\n",
      "\n",
      "> i m shy .\n",
      "= ma olen tagasihoidlik .\n",
      "< ma olen tagasihoidlik . <EOS>\n",
      "\n",
      "> i m glad to be of service .\n",
      "= mul on hea meel et sain aidata .\n",
      "< mul on hea meel et sain aidata . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cur_directory = os.getcwd()\n",
    "encoder_extension = '/encoder1.pt'\n",
    "decoder_extension = '/attn_decoder1.pt'\n",
    "\n",
    "\n",
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1)\n",
    "encoder1.load_state_dict(torch.load(cur_directory + encoder_extension))\n",
    "attn_decoder1.load_state_dict(torch.load(cur_directory + decoder_extension))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets translate some examples ourselves!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([u'ta', u'kannab', u'prille', u'.', u'<EOS>'], \n",
       " \n",
       " Columns 0 to 5 \n",
       "  1.2173e-04  1.4168e-04  4.5228e-04  9.9905e-01  7.4620e-06  1.5921e-05\n",
       "  2.7236e-03  4.8768e-03  5.7507e-03  9.7666e-01  4.3451e-04  4.5482e-05\n",
       "  9.6990e-03  4.1964e-02  4.8244e-02  2.8661e-01  5.8008e-01  2.7047e-03\n",
       "  5.6223e-04  1.1337e-03  2.8264e-04  5.0078e-05  6.4354e-03  9.8839e-01\n",
       "  2.0690e-02  5.4637e-03  3.4085e-03  3.1946e-04  2.1417e-01  3.9842e-03\n",
       " \n",
       " Columns 6 to 9 \n",
       "  9.9560e-06  4.6939e-05  3.5089e-05  1.1824e-04\n",
       "  8.3330e-04  1.9691e-03  4.9448e-03  1.7595e-03\n",
       "  1.8052e-04  1.6959e-03  4.8112e-03  2.4002e-02\n",
       "  1.9472e-04  5.8804e-04  1.5384e-03  8.2694e-04\n",
       "  2.2546e-01  2.0228e-01  1.4411e-02  3.0982e-01\n",
       " [torch.FloatTensor of size 5x10])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(encoder1, attn_decoder1, \"he is wearing glasses .\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(\n",
    "        encoder1, attn_decoder1, input_sentence)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = he is wearing glasses\n",
      "output = ta kannab prille . <EOS>\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXMAAADtCAYAAABNoZUVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110afb090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluateAndShowAttention('he is wearing glasses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "cur_directory = os.getcwd()\n",
    "encoder_extension = '/encoder1.pt'\n",
    "decoder_extension = '/attn_decoder1.pt'\n",
    "\n",
    "\n",
    "torch.save(encoder1.state_dict(), cur_directory + encoder_extension)\n",
    "torch.save(attn_decoder1.state_dict(), cur_directory + decoder_extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
